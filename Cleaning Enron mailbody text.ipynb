{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0dacbff9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mail_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>please let know you still need curve shift</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>david coursey hope ahead what learned from tra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dear phillip this email automated notification...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>image image image image image image image dear...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>request request create date requested for reso...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           mail_text\n",
       "0         please let know you still need curve shift\n",
       "1  david coursey hope ahead what learned from tra...\n",
       "2  dear phillip this email automated notification...\n",
       "3  image image image image image image image dear...\n",
       "4  request request create date requested for reso..."
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# load the raw dataset\n",
    "df = pd.read_csv(\"Enron_mail_bodytext_preprocessed.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0fe7dbd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'a', \"how's\", 'through', 'don', 'y', 'm', 'will', 'i', 'how', 'in', \"it's\", \"shouldn't\", 'themselves', 'those', 'during', 'all', 'was', 'mustn', 'which', \"haven't\", \"he'd\", 'them', \"doesn't\", 'needn', 'from', 'ain', 'where', 'be', \"we'll\", 'these', 'yourselves', 'this', 'had', 'than', 'too', 'an', \"hasn't\", 'weren', 'o', \"you're\", 'some', 'at', 'our', \"she's\", 'once', 'by', 'yourself', 'again', 'wasn', 'ma', \"we've\", 'very', \"who's\", \"didn't\", 'wouldn', 'with', 'me', 'now', 'we', \"needn't\", 'can', \"we're\", 'hers', 'the', 'here', 'been', 'it', 'if', 'no', 'until', 'while', 'her', \"here's\", 'to', 'whom', 'below', 'his', 'haven', 're', 'he', 'itself', 'as', \"shan't\", 'more', 'll', 'does', 'him', \"mightn't\", 'have', 'didn', \"she'd\", 'any', 'having', 'on', 'do', 'am', 'ought', 'won', 'has', 'such', \"i'll\", 'hasn', 'were', \"you'll\", 'its', 'who', 'there', 'each', 'into', \"they're\", \"what's\", \"they'll\", \"weren't\", 'they', 'before', 't', 'so', 'myself', 'would', 's', \"wasn't\", 'why', 'of', 'when', \"where's\", 'and', 'shan', \"let's\", 'nor', 'should', \"should've\", \"wouldn't\", \"aren't\", \"he's\", 'not', 'mightn', 'other', 'is', \"that'll\", 'shouldn', 'then', \"couldn't\", 'between', 'my', \"i've\", 'about', \"that's\", \"we'd\", \"mustn't\", 'are', 've', 'because', 'for', 'hadn', \"i'm\", 'aren', 'doing', \"why's\", \"won't\", 'she', \"isn't\", 'both', 'isn', \"don't\", \"i'd\", 'ours', \"they'd\", 'off', 'own', 'd', 'under', 'up', 'being', 'out', 'only', 'doesn', 'couldn', 'you', 'himself', \"she'll\", 'but', 'ourselves', 'few', \"you'd\", 'most', 'their', 'or', 'after', 'against', \"there's\", 'that', \"hadn't\", 'over', 'theirs', 'above', 'cannot', 'yours', 'could', 'further', \"you've\", 'down', 'did', 'herself', 'what', \"they've\", 'just', \"can't\", \"he'll\", 'same', \"when's\", 'your'}\n",
      "<class 'list'>\n",
      "<class 'list'>\n",
      "211\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from gensim import corpora, models\n",
    "import pandas as pd\n",
    "import gensim\n",
    "import re\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim_models\n",
    "\n",
    "\n",
    "from stop_words import get_stop_words\n",
    "from nltk.corpus import stopwords\n",
    "STOPWORDS = set(stopwords.words('english'))\n",
    "stop_words = list(get_stop_words('en'))\n",
    "\n",
    "print((set(list(STOPWORDS)) | set(list(stop_words))))\n",
    "stopwords = list(set(list(STOPWORDS)) | set(list(stop_words)))\n",
    "print(type(list(STOPWORDS)))\n",
    "print(type((stop_words)))\n",
    "print(len(stopwords))\n",
    "\n",
    "# removing special characters from stopwords\n",
    "stopwords = [re.sub('[^a-z]+', '', word) for word in stopwords]\n",
    "\n",
    "# text with no stopwords\n",
    "df['no_stopwords_mail_text'] = df['mail_text'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stopwords)]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1e7b33a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    Word  Frequency\n",
      "0                  enron      36646\n",
      "1                 please      20267\n",
      "2                    new      19488\n",
      "3                  image      13911\n",
      "4                  email      13507\n",
      "...                  ...        ...\n",
      "110104      encoreepcors          1\n",
      "110105  acknowledgements          1\n",
      "110106         greenizan          1\n",
      "110107           jzuffer          1\n",
      "110108           accumap          1\n",
      "\n",
      "[110109 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "# finding the frequency of words\n",
    "p = Counter(\" \".join(df['no_stopwords_mail_text']).split()).most_common(110110)\n",
    "word_freq_df = pd.DataFrame(p, columns=['Word', 'Frequency'])\n",
    "print(word_freq_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "54f6b8ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>enron</td>\n",
       "      <td>36646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>please</td>\n",
       "      <td>20267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>new</td>\n",
       "      <td>19488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>image</td>\n",
       "      <td>13911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>email</td>\n",
       "      <td>13507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>energy</td>\n",
       "      <td>13329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>time</td>\n",
       "      <td>13328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>said</td>\n",
       "      <td>12579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>power</td>\n",
       "      <td>11999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>gas</td>\n",
       "      <td>11904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>may</td>\n",
       "      <td>11875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>information</td>\n",
       "      <td>11465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>market</td>\n",
       "      <td>9751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>one</td>\n",
       "      <td>9642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>business</td>\n",
       "      <td>9567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>also</td>\n",
       "      <td>9109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>day</td>\n",
       "      <td>8736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>know</td>\n",
       "      <td>8565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>week</td>\n",
       "      <td>7605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>get</td>\n",
       "      <td>7456</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Word  Frequency\n",
       "0         enron      36646\n",
       "1        please      20267\n",
       "2           new      19488\n",
       "3         image      13911\n",
       "4         email      13507\n",
       "5        energy      13329\n",
       "6          time      13328\n",
       "7          said      12579\n",
       "8         power      11999\n",
       "9           gas      11904\n",
       "10          may      11875\n",
       "11  information      11465\n",
       "12       market       9751\n",
       "13          one       9642\n",
       "14     business       9567\n",
       "15         also       9109\n",
       "16          day       8736\n",
       "17         know       8565\n",
       "18         week       7605\n",
       "19          get       7456"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_freq_df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b9280a76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "89905"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# less frequent words\n",
    "len(word_freq_df[word_freq_df['Frequency'] < 10]['Word'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c675e89e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "746"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# most frequent words\n",
    "len(word_freq_df[word_freq_df['Frequency'] > 1000]['Word'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c1bd11b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "frequent_words = word_freq_df[word_freq_df['Frequency'] > 1000]['Word'].values\n",
    "rare_words = word_freq_df[word_freq_df['Frequency'] < 10]['Word'].values\n",
    "\n",
    "# removing the more frequent words and less frequent words\n",
    "df['no_frequent_words_mail_text'] = df['no_stopwords_mail_text'].apply(lambda x: ' '.join([word for word in x.split() if word not in (frequent_words)]))\n",
    "df['no_rare_words_mail_text'] = df['no_frequent_words_mail_text'].apply(lambda x: ' '.join([word for word in x.split() if word not in (rare_words)]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4fcc3d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# storing the preprocessed mail text in csv\n",
    "df['no_rare_words_mail_text'].to_csv(\"no_rare_words_mail_text.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf0c2c2e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64f66182",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a47e8c1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
